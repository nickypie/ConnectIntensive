# ConnectIntensive
Jupyter Notebooks for the Connect Intensive MLND Program

# Lesson Notebooks
  - `lesson-00.ipynb` : Hello Jupyter Notebook!
    - A "hello world" notebook to introduce the Jupyter IDE
    - Introduces import statements for commonly-used modules and packages
  - `lesson-01.ipynb` : An intro to Statistical Analysis using `pandas`
    - Introduces the `Series` and `DataFrame` objects in `pandas`
    - Defines categorical variables
    - Covers basic descriptive statistics: mean, median, min/max
    - Label-based `.loc` and index-based location `.iloc`
    - Boolean indexing, how to slice a `DataFrame`
    - Exercises in exploratory data analysis, emphasizing `groupby` and `plot`
  - `lesson-02.ipynb` : Working with the Enron Data Set
    - Covers the `pickle` module for saving objects
    - Magic functions in Jupyter notebooks
    - Use of the `stack` and `unstack` functions
    - Exercises in exploratory data analysis on the Enron data set
  - `lesson-03-part-01.ipynb` : Building and Evaluating Models with `sklearn`
    - Perform exploratory data analysis on a dataset
    - Tidy a data set so that it will be compatible with the `sklearn` library
  - `lesson-03-part-02.ipynb` : Building and Evaluating Models with `sklearn`
    - Make decision tree classifiers on the tidied dataset from part 01
    - Compute the accuracy of a model on both the training and validation (testing) data
    - Adjust hyperparameters to see the effects on model accuracy
    - Visualize decision trees and introduce the Gini impurity
  - `lesson-04-part-01.ipynb` : Bayes NLP Mini-Project
    - Understand how Bayes Rule derives from conditional probability
    - Write methods, applying Bayesian learning, to simple word-prediction tasks
    - Practice with `str.split()` and python dictionaries
  - `lesson-05.ipynb` : Classification with Support Vector Machines
    - Introduces additional plotting functionality in `matplotlib.pyplot`
      - Boxplots for depicting interquartile range (IQR), median, max, min, outliers
      - Scatterplots for 2-D representation of two features.
    - Introduction to Support Vector Machines in `sklearn`
      - An introduction to kernels
      - Hard-margin versus soft-margin SVMs
      - Overview of `SVC` hyperparameters: `C`, `gamma`, `degree`, etc.
    - Visualize decision boundaries resulting from the different kernels
    - Practice with `GridSearchCV`
