{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect Intensive - Machine Learning Nanodegree\n",
    "# Lesson 06: Clustering and Dimensionality Reduction\n",
    "# Part 01: Clustering Mini Project\n",
    "\n",
    "## Objectives\n",
    "  - Perform [k-means clustering](http://scikit-learn.org/stable/modules/clustering.html#k-means) on the Enron Data Set.\n",
    "  - Visualize different clusters that form before and after feature scaling.\n",
    "  - Plot decision boundaries that arise from k-means clustering using two features.\n",
    "  \n",
    "## Prerequisites\n",
    "  - You should have the following python packages installed:\n",
    "    - [matplotlib](http://matplotlib.org/index.html)\n",
    "    - [numpy](http://www.scipy.org/scipylib/download.html)\n",
    "    - [pandas](http://pandas.pydata.org/getpandas.html)\n",
    "    - [sklearn](http://scikit-learn.org/stable/install.html)\n",
    "  - Lesson 02 in [the ConnectIntensive repo](https://github.com/nickypie/ConnectIntensive) introduces the Enron Data Set that will be used in this notebook\n",
    "    - You should have cloned [**ud120-projects** repo](https://github.com/udacity/ud120-projects) to your local machine, and you'll need the full path for this repo on your machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Mini-Project\n",
    "\n",
    "This Jupyter Notebook is intended to provide a friendly guide through the \"Clustering Mini-Project\" lesson... but if you're feeling pretty confident about your Python skills, consider going off-script! Try to work through the lesson on your own -- you may encounter some snags, and you can always refer back to this Notebook if you need a little push forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "As usual, we start by importing some useful libraries and modules. Don't worry if you get a warning message when importing `matplotlib` -- it just needs to build the font cache, and the warning is just to alert you that this may take a while the first time the cell is run.\n",
    "\n",
    "**Run** the cell below to import useful libraries for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(\"Successfully imported numpy! (Version {})\".format(np.version.version))\n",
    "except ImportError:\n",
    "    print(\"Could not import numpy!\")\n",
    "\n",
    "    \n",
    "try:\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.style.use('ggplot')\n",
    "    print(\"Successfully imported matplotlib.pyplot! (Version {})\".format(matplotlib.__version__))\n",
    "except ImportError:\n",
    "    print(\"Could not import matplotlib.pyplot!\")\n",
    "\n",
    "    \n",
    "try:\n",
    "    import pandas as pd\n",
    "    print(\"Successfully imported pandas! (Version {})\".format(pd.__version__))\n",
    "    pd.options.display.max_rows = 10\n",
    "except ImportError:\n",
    "    print(\"Could not import pandas!\")\n",
    "\n",
    "    \n",
    "try:\n",
    "    from IPython.display import display\n",
    "    print(\"Successfully imported display from IPython.display!\")\n",
    "except ImportError:\n",
    "    print(\"Could not import display from IPython.display\")\n",
    "    \n",
    "try:\n",
    "    import sklearn\n",
    "    print(\"Successfully imported sklearn! (Version {})\".format(sklearn.__version__))\n",
    "    skversion = int(sklearn.__version__[2:4])\n",
    "except ImportError:\n",
    "    print(\"Could not import sklearn!\")\n",
    "\n",
    "try:\n",
    "    import pickle\n",
    "    print(\"Successfully imported pickle!\")\n",
    "except ImportError:\n",
    "    print(\"Could not import pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A little review -- Magic Functions and `pickle`\n",
    "\n",
    "We're going to use the Enron Data Set from the [**ud120-projects** repo](https://github.com/udacity/ud120-projects) in this notebook. We last used this data set in [lesson-02.ipynb](https://github.com/nickypie/ConnectIntensive/blob/master/lesson-02.ipynb) to hone our `pandas` skills. In this notebook, we're going to perform [k-means clustering](http://scikit-learn.org/stable/modules/clustering.html#k-means) on the data to see if certain patterns emerge.\n",
    "\n",
    "Recall that we had used the Jupyter Notebook [line magic](http://ipython.readthedocs.io/en/stable/interactive/tutorial.html#magics-explained):\n",
    "\n",
    "`%cd \"...\"`\n",
    "\n",
    "By replacing the ellipses with a path, we can use this line magic to change the working directory for this Jupyter Notebook session.\n",
    "\n",
    "**Update** the Magic Function `%cd \"...\"` in the cell below to reflect the correct path of the **ud120-projects** directory on your local machine.\n",
    "\n",
    "Then **run** the cell to use [the pickle module](https://docs.python.org/2/library/pickle.html) to retrieve the Enron data dictionary. A message will print if the data dictionary was successfully loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Be sure to write the full path, up to and including \"ud120-projects\"\n",
    "%cd \"/Users/nick/Documents/Udacity/ud120-projects\"\n",
    "\n",
    "try:\n",
    "    pickle_file = open(\"final_project/final_project_dataset.pkl\", \"r\")\n",
    "    enron_data = pickle.load(pickle_file)\n",
    "    pickle_file.close()\n",
    "    print(\"Enron data loaded successfully!\")\n",
    "except IOError:\n",
    "    print(\"No such file or directory! (Is there a problem with the path?)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "We couldn't find *all* the details for each person involved with the Enron scandal, so the Enron data set has some missing values denoted by `\"NaN\"` entries in the data dictionary. Because we must pass numeric arrays into `sklearn` modules, we need to preprocess the data dictionary a bit before we can use [`sklearn.cluster.KMeans()`](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html).\n",
    "\n",
    "**Run** the cell below to complete our preprocessing steps:\n",
    "  - Remove the outlier: there is an entry `\"TOTAL\"` in the data dictionary containing totals of all features.\n",
    "  - Create a pandas `DataFrame` object from the Enron data dictionary\n",
    "  - Take the **transpose** of the Enron `DataFrame` with [`DataFrame.T`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.T.html), so that rows correspond to individuals (instances). Recall that we used [`stack()` and `unstack()`](http://pandas.pydata.org/pandas-docs/stable/reshaping.html#reshaping-by-stacking-and-unstacking) last time to accomplish this task... but taking the transpose is more straightforward.\n",
    "  - Impute missing values: Replace all \"NaN\" values in the DataFrame with **zeroes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing the Enron dataset:\n",
    "# there's an outlier--remove it! \n",
    "enron_data.pop(\"TOTAL\", 0)\n",
    "\n",
    "# Create a DataFrame object from the Enron data dictionary\n",
    "enron_df = pd.DataFrame.from_dict(enron_data)\n",
    "\n",
    "# Take the transpose (.T) of the Enron DataFrame,\n",
    "# so that rows of the DataFrame correspond to individuals\n",
    "enron_df = enron_df.T\n",
    "\n",
    "# Change all entries in the DataFrame with \"NaN\" to zeroes.\n",
    "enron_df[enron_df == \"NaN\"] = 0\n",
    "\n",
    "# Display the DataFrame after preprocessing is complete\n",
    "display(enron_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering - Cluster Visualization\n",
    "In this mini-project, you will perform [k-means clustering](https://en.wikipedia.org/wiki/K-means_clustering) on the Enron Data Set. K-means clustering is a variant of [Lloyd's Algorithm](https://en.wikipedia.org/wiki/Lloyd's_algorithm) or Voronoi Iteration. We're going to define a function `DrawClusters()` that will allow us to visualize the resulting clusters. \n",
    "\n",
    "**Read** the cell below to get an idea of what happens in the `DrawClusters()` function. The `DrawFunction()` function is a modified version of [the `Draw()` function from `\"ud120-projects/kmeans/k_means_cluster.py\"`](https://github.com/udacity/ud120-projects/blob/master/k_means/k_means_cluster.py). Here's a quick summary of changes:\n",
    "  - `DrawClusters()` now works with the `pandas` `DataFrame` object `enron_df`.\n",
    "  - Some of the functionality from `\"ud120-projects/tools/feature_format.py\"` is incorporated into `DrawClusters()`:\n",
    "    - The ability to remove instances with **all** zeroes from k-means clustering\n",
    "    - The ability to remove instances with **any** zeroes from k-means clustering\n",
    "    - The ability to rescale features, remapping them to the interval [0,1]\n",
    "  - `DrawClusters()` also draws the resulting decision boundary when `feature_list` contains only two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def DrawClusters(n_clusters = 2,\\\n",
    "                 feature_list = [\"salary\",\"exercised_stock_options\"],\\\n",
    "                 remove_any_zeroes = False,\\\n",
    "                 remove_all_zeroes = True,\\\n",
    "                 rescale_features = False,\\\n",
    "                 x_label = 'Salary',\\\n",
    "                 y_label = 'Exercised Stock Options'):\n",
    "    \n",
    "    '''\n",
    "    Plots k-means clusters trained on a list of features from enron_df\n",
    "    @param n_clusters:        an integer, the number of clusters to form.\n",
    "    @param feature_list:      a list of strings, the features to use in KMeans clustering\n",
    "                              (first two features in the list will be plotted on x,y axes)\n",
    "                              if len(feature_list) == 2, decision boundaries will be plotted \n",
    "    @param remove_any_zeroes: a boolean, whether or not to remove points when clustering\n",
    "                              that contain ANY zeroes\n",
    "    @param remove_all_zeroes: a boolean, whether or not to remove points when clustering\n",
    "                              that contain ONLY zeroes\n",
    "    @param rescale_features:  a boolean, whether or not to rescale features from 0 to 1\n",
    "    @param x_label:           a string, the x-axis label of the plot\n",
    "    @param y_label:           a string, the y-axis label of the plot\n",
    "    '''\n",
    "\n",
    "    # Initialize color and shape lists for scatterplot\n",
    "    # Note: need to lengthen the color and shape lists if\n",
    "    #       you want to use more than 7 clusters.\n",
    "    color_list = [\"r\",\"g\",\"b\",\"c\",\"m\",\"y\",\"k\"]\n",
    "    shape_list = [\"^\",\"o\",\"s\",\"v\",\"D\",\"<\",\"h\"]\n",
    "    \n",
    "    # Initialize figure and axes:\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # We are going to cluster the data using KMeans,\n",
    "    # based on the features from the parameter feature_list.\n",
    "    X = enron_df[feature_list]\n",
    "    \n",
    "    # We can see if clustering correctly identified POIs\n",
    "    y = enron_df['poi']\n",
    "    \n",
    "    # If desired, remove instances where ANY feature is zero\n",
    "    if remove_any_zeroes:\n",
    "        X = X[~(X.T == 0).any()]\n",
    "        \n",
    "    # If desired, remove instances where ALL features are zeroes\n",
    "    if remove_all_zeroes:\n",
    "        X = X[~(X.T == 0).all()]\n",
    "\n",
    "    # If desired, rescale features\n",
    "    if rescale_features:\n",
    "        for feature in X.columns:\n",
    "            min_feature = X[~(X[feature] == 0)][feature].min()\n",
    "            max_feature = X[~(X[feature] == 0)][feature].max()\n",
    "            range_feature = max_feature - min_feature\n",
    "            X[feature] = (X[feature] - min_feature)*1.0 / range_feature\n",
    "            \n",
    "    # If we removed any instances above, we need to keep \n",
    "    # only the corresponding instances in y (the POI Series)\n",
    "    y = y.loc[X.index]\n",
    "    \n",
    "    # By default, the first two features in the list are chosen\n",
    "    # as the x and y features.\n",
    "    x_feature = feature_list[0]\n",
    "    y_feature = feature_list[1]\n",
    "\n",
    "    # Determine the min & max values of x_feature, compute the range,\n",
    "    # and pad the minimum and maximum x values by 5% of the range\n",
    "    x_min, x_max = X[x_feature].min(), X[x_feature].max()\n",
    "    x_range = x_max - x_min\n",
    "    x_min -= x_range * 0.05\n",
    "    x_max += x_range * 0.05\n",
    "    \n",
    "    # Determine the min & max values of y_feature, compute the range,\n",
    "    # and pad the minimum and maximum y values by 5% of the range\n",
    "    y_min, y_max = X[y_feature].min(), X[y_feature].max()\n",
    "    y_range = y_max - y_min\n",
    "    y_min -= y_range * 0.05\n",
    "    y_max += y_range * 0.05\n",
    "    \n",
    "    # Compute k-means clustering.\n",
    "    kmns = KMeans(n_clusters = n_clusters).fit(X)\n",
    "\n",
    "    \n",
    "    # We can visualize the decision boundaries if the \n",
    "    # k-means clusters are formed from just two features\n",
    "    if len(feature_list) == 2:\n",
    "        # Return coordinate matrices xx and yy from arrays\n",
    "        xx, yy = np.meshgrid(np.linspace(x_min, x_max, num = 500),\\\n",
    "                             np.linspace(y_min, y_max, num = 500))\n",
    "\n",
    "        # Use the clustering to make a prediction for each point\n",
    "        # in the coordinate matrices, then reshape for plotting.\n",
    "        Z = kmns.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        # Plot semitransparent filled contours for the\n",
    "        # cluster decision boundaries\n",
    "        ax.contourf(xx, yy, Z,\\\n",
    "                    levels=list(np.arange(n_clusters+1)-0.5),\\\n",
    "                    colors=tuple(color_list[:n_clusters]),alpha=0.2)\n",
    "    \n",
    "    # Scatterplot all of the points in each cluster,\n",
    "    # with each cluster a different color and shape\n",
    "    pred = kmns.predict(X)\n",
    "    for cluster_idx in range(n_clusters):\n",
    "        X_cluster = X[pred == cluster_idx]\n",
    "        ax.scatter(X_cluster[x_feature], X_cluster[y_feature],\\\n",
    "                   s=30, marker = shape_list[cluster_idx],\\\n",
    "                   edgecolor='k', facecolor=color_list[cluster_idx], alpha=0.8)\n",
    "        \n",
    "    # Denote the centroids of each cluster with a white X\n",
    "    centers = kmns.cluster_centers_\n",
    "    if len(feature_list) == 2:\n",
    "        for center in centers:\n",
    "            ax.scatter(center[0],center[1],marker='x',facecolor=\"w\",linewidth=3,s=50)\n",
    "            \n",
    "    # Set the title and axes labels, and adjust the aspect ratio for rescaled data\n",
    "    if rescale_features:\n",
    "        title   = ax.set_title(\"K Means - {} Clusters (Rescaled)\".format(n_clusters))\n",
    "        # Force the axes aspect ratio to be plotted equally\n",
    "        ax.set(adjustable='box-forced', aspect='equal')\n",
    "    else:\n",
    "        title   = ax.set_title(\"K Means - {} Clusters\".format(n_clusters))\n",
    "    x_label = ax.set_xlabel(x_label)\n",
    "    y_label = ax.set_ylabel(y_label)\n",
    "    \n",
    "    # Set the x- and y-axis limits using the padded minimum and maximum values\n",
    "    xlim = ax.set_xlim((x_min,x_max))\n",
    "    ylim = ax.set_ylim((y_min,y_max))\n",
    "    \n",
    "print(\"DrawClusters() is ready to use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "The exercises below correspond to the quizzes in the Clustering Mini Project. As you complete this notebook, you may check your progress by entering the solutions into the corresponding quizzes.\n",
    "\n",
    "## Quiz: Clustering Features\n",
    "**Run** the cell below, which will create a scatterplot of the data, then look at the resulting figure. What clusters you would expect to arise from this data if 2 clusters are created? That is, how would you partition the data into two clusters?\n",
    "\n",
    "In the accompanying quiz, \"Quiz: Clustering Features\", enter the two feature names from the cell below that we'll use in k-means clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(enron_df[\"salary\"],enron_df[\"exercised_stock_options\"])\n",
    "title   = ax.set_title(\"Exercised Stock Options vs. Salary\")\n",
    "xlabel  = ax.set_xlabel(\"Salary\")\n",
    "ylabel  = ax.set_ylabel(\"Exercised Stock Options\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz: Deploying Clustering\n",
    "**Run** the cell below, which will perform k-means clustering on the data using only the `salary` and `exercised_stock_options` features. Look at the resulting clusters -- because we're only using two features, we can also plot the decision boundary in the plane.\n",
    "\n",
    "In the accompanying quiz, \"Quiz: Deploying Clusters\", state whether the two clusters partition the data as you expected... there's no wrong answer here :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DrawClusters(n_clusters = 2,\\\n",
    "             feature_list = [\"salary\",\"exercised_stock_options\"],\\\n",
    "             remove_any_zeroes = False,\\\n",
    "             remove_all_zeroes = True,\\\n",
    "             rescale_features = False,\\\n",
    "             x_label = 'Salary',\\\n",
    "             y_label = 'Exercised Stock Options')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice in the cluster scatterplot that the decision boundary between the two centroids (denoted by white X symbols) does not appear to be perpendicular to the line-of-centers between the centroids... do you understand why?\n",
    "\n",
    "## Quiz: Clustering with 3 Features\n",
    "\n",
    "**Run** the cell below to add a third feature to features_list, `total_payments`. The clustering is now performed using 3 input features instead of 2 (obviously we can still only visualize the original 2 features, `salary` and `exercised_stock_options`). We also can't visualize the decision boundary anymore, because the points all have different values for the `total_payments` feature. Compare the clusterings to those you obtained with 2 input features. Do any points switch clusters? How many? This new clustering, using 3 features, couldn’t have been guessed by eye -- it was the k-means algorithm that identified it.\n",
    "\n",
    "In the accompanying quiz, \"Quiz: Deploying Clusters\", state how many points, if any, change clusters after adding the `total_payments` feature to `feature_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DrawClusters(n_clusters = 2,\\\n",
    "             feature_list = [\"salary\",\"exercised_stock_options\",\"total_payments\"],\\\n",
    "             remove_any_zeroes = False,\\\n",
    "             remove_all_zeroes = True,\\\n",
    "             rescale_features = False,\\\n",
    "             x_label = 'Salary',\\\n",
    "             y_label = 'Exercised Stock Options')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz: Stock Option Range\n",
    "\n",
    "We're going to cover [feature scaling](http://sebastianraschka.com/Articles/2014_about_feature_scaling.html), a type of preprocessing that you should perform before some classification and regression tasks. Here’s a sneak preview that should call your attention to the general outline of what feature scaling does.\n",
    "\n",
    "What are the **maximum** and **minimum** values taken by the `exercised_stock_options` feature used in this example? You will enter these values in the corresponding quiz, \"Quiz: Stock Option Range.\"\n",
    "\n",
    "**Note:** In one of the preprocessing steps, all `NaN` entries in `enron_df` were changed to zeroes. We do this because all features passed into `sklearn` classifiers must be numeric. So, to answer this question, you may want to look at the original data *before* this preprocessing step was performed. To help with this task, **run** the cell below to create the data frame `df` from the `enron_data` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame object from the Enron data dictionary\n",
    "df = pd.DataFrame.from_dict(enron_data)\n",
    "\n",
    "# Take the transpose (.T) of the Enron DataFrame,\n",
    "# so that rows of the DataFrame correspond to individuals\n",
    "df = df.T\n",
    "\n",
    "print(\"DataFrame df has been created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz: Salary Range\n",
    "\n",
    "What are the **maximum** and **minimum** values taken by the `salary` feature used in this example? You will enter these values in the corresponding quiz, \"Quiz: Salary Range.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz: Clustering Changes\n",
    "\n",
    "**Run** the cell below to plot the original two clusters, with the features `salary` and `exercised_stock_options`. Note that the features are not yet scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DrawClusters(n_clusters = 2,\\\n",
    "             feature_list = [\"salary\",\"exercised_stock_options\"],\\\n",
    "             remove_any_zeroes = False,\\\n",
    "             remove_all_zeroes = True,\\\n",
    "             rescale_features = False,\\\n",
    "             x_label = 'Salary',\\\n",
    "             y_label = 'Exercised Stock Options')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now **run** the cell below to do simple feature rescaling, mapping the original ranges of `exercised_stock_options` and `salary` onto the interval [0,1]. You should find that some of the points change clusters! You should also find that these clusters are not as stable as in the previous examples. **Run** the cell multiple times. You should find that the reported clusters are sometimes different, depending on where the centroids were initialized for k-means.\n",
    "\n",
    "In the accompanying quiz, \"Quiz: Clustering Changes\", one possible clustering result is depicted after feature rescaling. **Check** the boxes next to points that change clusters after feature rescaling in this example scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DrawClusters(n_clusters = 2,\\\n",
    "             feature_list = [\"salary\",\"exercised_stock_options\"],\\\n",
    "             remove_any_zeroes = False,\\\n",
    "             remove_all_zeroes = True,\\\n",
    "             rescale_features = True,\\\n",
    "             x_label = 'Salary',\\\n",
    "             y_label = 'Exercised Stock Options')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Exploration\n",
    "\n",
    "At this point, you've completed the k-means mini project -- congratulations!  Below are a few more examples of k-means clustering on the Enron Data Set. Feel free to **run** these cells to see additional k-means clustering examples.\n",
    "\n",
    "You can also read [the `sklearn` documentation on `sklearn.cluster.KMeans`](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) and [the KMeans user guide](http://scikit-learn.org/stable/modules/clustering.html#k-means) to learn more about the algorithm and about other parameters that you may set when calling KMeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example of k-means clustering with 3 clusters, different features, rescaled\n",
    "\n",
    "DrawClusters(n_clusters = 3,\\\n",
    "             feature_list = [\"total_payments\",\"exercised_stock_options\"],\\\n",
    "             remove_any_zeroes = False,\\\n",
    "             remove_all_zeroes = True,\\\n",
    "             rescale_features = True,\\\n",
    "             x_label = 'Total Payments',\\\n",
    "             y_label = 'Exercised Stock Options')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example of k-means clustering with 7 clusters, rescaled\n",
    "\n",
    "DrawClusters(n_clusters = 7,\\\n",
    "             feature_list = [\"salary\",\"exercised_stock_options\"],\\\n",
    "             remove_any_zeroes = False,\\\n",
    "             remove_all_zeroes = True,\\\n",
    "             rescale_features = True,\\\n",
    "             x_label = 'Salary',\\\n",
    "             y_label = 'Exercised Stock Options')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example of k-means clustering with 3 clusters, different features, rescaled\n",
    "\n",
    "DrawClusters(n_clusters = 3,\\\n",
    "             feature_list = [\"restricted_stock\",\"total_stock_value\"],\\\n",
    "             remove_any_zeroes = False,\\\n",
    "             remove_all_zeroes = True,\\\n",
    "             rescale_features = True,\\\n",
    "             x_label = 'Restricted Stock',\\\n",
    "             y_label = 'Total Stock Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
