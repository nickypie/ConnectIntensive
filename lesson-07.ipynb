{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect Intensive - Machine Learning Nanodegree\n",
    "# Lesson 07: Feature Selection\n",
    "\n",
    "## Objectives\n",
    "  - Define the Chi-Squared $(\\chi^2)$ test-statistic and Pearson's Chi-Squared Test\n",
    "  - Perform univariate feature selection using <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html\">the `SelectKBest` class</a> from `sklearn`.\n",
    "  - Perform recursive feature elimination (RFE) using <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\">the `RFE` class</a> from `sklearn`.\n",
    "  - Determine the optimal number of features to retain using RFE with cross-validation (RFECV) and <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html\">the `RFECV` class</a> from `sklearn`.\n",
    "  \n",
    "## Prerequisites\n",
    "  - You should have the following python packages installed:\n",
    "    - [matplotlib](http://matplotlib.org/index.html)\n",
    "    - [numpy](http://www.scipy.org/scipylib/download.html)\n",
    "    - [pandas](http://pandas.pydata.org/getpandas.html)\n",
    "    - [sklearn](http://scikit-learn.org/stable/install.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "As usual, we start by importing some useful libraries and modules. Don't worry if you get a warning message when importing `matplotlib` -- it just needs to build the font cache, and the warning is just to alert you that this may take a while the first time the cell is run.\n",
    "\n",
    "**Run** the cell below to import useful libraries for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(\"Successfully imported numpy! (Version {})\".format(np.version.version))\n",
    "except ImportError:\n",
    "    print(\"Could not import numpy!\")\n",
    "\n",
    "    \n",
    "try:\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.style.use('ggplot')\n",
    "    print(\"Successfully imported matplotlib.pyplot! (Version {})\".format(matplotlib.__version__))\n",
    "except ImportError:\n",
    "    print(\"Could not import matplotlib.pyplot!\")\n",
    "\n",
    "    \n",
    "try:\n",
    "    import pandas as pd\n",
    "    print(\"Successfully imported pandas! (Version {})\".format(pd.__version__))\n",
    "    pd.options.display.max_rows = 10\n",
    "except ImportError:\n",
    "    print(\"Could not import pandas!\")\n",
    "\n",
    "    \n",
    "try:\n",
    "    from IPython.display import display\n",
    "    print(\"Successfully imported display from IPython.display!\")\n",
    "except ImportError:\n",
    "    print(\"Could not import display from IPython.display\")\n",
    "    \n",
    "try:\n",
    "    import sklearn\n",
    "    print(\"Successfully imported sklearn! (Version {})\".format(sklearn.__version__))\n",
    "    skversion = int(sklearn.__version__[2:4])\n",
    "except ImportError:\n",
    "    print(\"Could not import sklearn!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Mushroom Data Set\n",
    "The [UCI Machine Learning Repository (MLR)](https://archive.ics.uci.edu/ml/index.html) maintains datasets as a service to the machine learning community. One of those datasets is the [Mushroom Data Set](https://archive.ics.uci.edu/ml/datasets/Mushroom), drawn from **The Audubon Society Field Guide to North American Mushrooms** *(1981)*. There are 8124 instances in the dataset, with 22 categorical features that can be used to predict whether a mushroom is edible or poisonous. The data set information from the UCI MLR is as follows:\n",
    "> *\"This data set includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family (pp. 500-525). Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous one. The Guide clearly states that there is no simple rule for determining the edibility of a mushroom; no rule like \"leaflets three, let it be\" for Poisonous Oak and Ivy.\"*\n",
    "\n",
    "The first column in the dataset is the **edible** feature, describing whether a mushroom is (e)dible or (p)oisonous.\n",
    "\n",
    "The remaining 22 columns in the dataset correspond to the following 22 features that describe the mushrooms:\n",
    "  1. **cap-shape:** bell=b, conical=c, convex=x, flat=f, knobbed=k, sunken=s\n",
    "  2. **cap-surface:** fibrous=f, grooves=g, scaly=y, smooth=s\n",
    "  3. **cap-color:** brown=n, buff=b, cinnamon=c, gray=g, green=r, pink=p, purple=u, red=e, white=w, yellow=y\n",
    "  4. **bruises:** bruises=t, no=f\n",
    "  5. **odor:** almond=a, anise=l, creosote=c, fishy=y, foul=f, musty=m, none=n, pungent=p, spicy=s\n",
    "  6. **gill-attachment:** attached=a, descending=d, free=f, notched=n\n",
    "  7. **gill-spacing:** close=c, crowded=w, distant=d\n",
    "  8. **gill-size:** broad=b, narrow=n\n",
    "  9. **gill-color:** black=k, brown=n, buff=b, chocolate=h, gray=g, green=r, orange=o, pink=p, purple=u, red=e, white=w, yellow=y\n",
    "  10. **stalk-shape:** enlarging=e, tapering=t\n",
    "  11. **stalk-root:** bulbous=b, club=c, cup=u, equal=e, rhizomorphs=z, rooted=r, missing=?\n",
    "  12. **stalk-surface-above-ring:** fibrous=f, scaly=y, silky=k, smooth=s\n",
    "  13. **stalk-surface-below-ring:** fibrous=f, scaly=y, silky=k, smooth=s\n",
    "  14. **stalk-color-above-ring:** brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y\n",
    "  15. **stalk-color-below-ring:** brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y\n",
    "  16. **veil-type:** partial=p, universal=u\n",
    "  17. **veil-color:** brown=n, orange=o, white=w, yellow=y\n",
    "  18. **ring-number:** none=n, one=o, two=t\n",
    "  19. **ring-type:** cobwebby=c, evanescent=e, flaring=f, large=l, none=n, pendant=p, sheathing=s, zone=z\n",
    "  20. **spore-print-color:** black=k, brown=n, buff=b, chocolate=h, green=r, orange=o, purple=u, white=w, yellow=y\n",
    "  21. **population:** abundant=a, clustered=c, numerous=n,scattered=s, several=v, solitary=y\n",
    "  22. **habitat:** grasses=g, leaves=l, meadows=m, paths=p, urban=u, waste=w, woods=d\n",
    "\n",
    "**Run** the cell below to read the mushroom data from the UCI MLR into a `pandas` `DataFrame` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mush_url = \"http://mlr.cs.umass.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\"\n",
    "mush_names = [\"edible\",\"cap-shape\",\"cap-surface\",\"cap-color\",\"bruises\",\"odor\",\"gill-attachment\",\\\n",
    "         \"gill-spacing\",\"gill-size\",\"gill-color\",\"stalk-shape\",\"stalk-root\",\\\n",
    "         \"stalk-surface-above-ring\",\"stalk-surface-below-ring\",\"stalk-color-above-ring\",\\\n",
    "         \"stalk-color-below-ring\",\"veil-type\",\"veil-color\",\"ring-number\",\"ring-type\",\\\n",
    "         \"spore-print-color\",\"population\",\"habitat\"]\n",
    "\n",
    "mush_df = pd.read_csv(mush_url, names=mush_names, header=None)\n",
    "\n",
    "display(mush_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 22 categorical features in the mushroom data, but if we get the indicator variables (dummy variables) for each of the categorical features (using either [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) or [`sklearn.preprocessing.OneHotEncoder()`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)), there will be even more features to choose from, leaving us victims to the curse of dimensionality. This lesson covers some techniques to reduce the dimensionality of the problem, so that we'll be victims no more!\n",
    "\n",
    "To start, we'll need to cover the Chi-Squared test, which is one way to determine the predictive power for a given feature -- namely, how likely are two features to be independent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contingency Tables and Pearson's Chi-Squared Test\n",
    "\n",
    "We'll step away from the UCI MLR mushroom dataset for a bit to deal with simpler numbers for this example. Suppose we have a collection 100 mushrooms. Half of these mushrooms (50) have bruises, and half (50) do not. Also, half of these mushrooms (50) are **edible** and half (50) are **poisonous**. A [**contingency table**](https://en.wikipedia.org/wiki/Contingency_table) (also known as a **cross tabulation** or **crosstab**) is a matrix that displays the *multivariate* frequency distribution of the variables. Below is one possible **observed** contingency table:\n",
    "\n",
    "| **edible**  | **e** | **p** | \n",
    "|-------------|-------|-------| \n",
    "| **bruises** |       |       |\n",
    "| **f**       |    20 |    30 | \n",
    "| **t**       |    30 |    20 |\n",
    "\n",
    "The **columns** of this contingency table correspond to edible (**e**) and poisonous (**p**) mushrooms, respectively. The **rows** correspond to the absence (**f**) or presence (**t**) of bruises on the mushroom, respectively. In this example, there are 20 edible mushrooms without bruises and 30 edible mushrooms with bruises. There are 30 poisonous mushrooms without bruises and 20 poisonous mushrooms with bruises.\n",
    "\n",
    "We might be wondering, based on the observed contingency table above, are these two features (edible and bruises) *independent*? [Pearson's Chi-Squared Test](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test) is one way to predict how likely is the hypothesis that two features are independent. First, we need to compute the **expected** or **theoretical** contingency table for independent features. For example, what frequency of edible mushrooms with bruises would we expect from a set of 100 mushrooms where 50 are edible and 50 have bruises? We could compute this as follows:\n",
    "\n",
    "$$ \\begin{array}{c}\\text{Theoretical}\\\\\\text{frequency of}\\\\\\text{edible mushrooms}\\\\\\text{with bruises}\\end{array} = \\left(\\begin{array}{c}\\text{Probability of}\\\\\\text{mushroom being}\\\\\\text{edible}\\end{array}\\right) \\times \\left(\\begin{array}{c}\\text{Probability of}\\\\\\text{mushroom having}\\\\\\text{bruises}\\end{array}\\right) \\times\n",
    "\\left(\\begin{array}{c}\\text{Total}\\\\\\text{number of}\\\\\\text{mushrooms}\\end{array}\\right)=\\left(\\frac{50}{100}\\right)\\left(\\frac{50}{100}\\right)\\left(\\vphantom{\\frac{50}{100}}100\\right)=\\boxed{\\ 25\\ }$$\n",
    "\n",
    "We can repeat this calculation for each entry in the contingency table to arrive at the **theoretical** or **expected** contingency table:\n",
    "\n",
    "| **edible**  | **e** | **p** | \n",
    "|-------------|-------|-------| \n",
    "| **bruises** |       |       |\n",
    "| **f**       |    25 |    25 | \n",
    "| **t**       |    25 |    25 |\n",
    "\n",
    "Now that we have the observed and expected frequencies, we can compute $\\chi^2$, the test-statistic:\n",
    "\n",
    "$$\\boxed{\\chi^2=\\sum_{i=1}^n\\frac{\\left(E_i-O_i\\right)^2}{E_i}}$$\n",
    "\n",
    "Where we have introduced the following symbols:\n",
    "  - $\\chi^2$ is Pearson's cumulative test-statistic, which asymptotically approaches a [$\\chi^2$ distribution](https://en.wikipedia.org/wiki/Chi-squared_distribution)\n",
    "  - $n$ is the number of cells in the contingency table (in our example, $n=4$)\n",
    "  - $E_i$ is the **expected** or **theoretical** frequency for the $i^{\\text{th}}$ cell of the contingency table.\n",
    "  - $O_i$ is the **observed** or **actual** frequency for the $i^{\\text{th}}$ cell of the contingency table.\n",
    "  \n",
    "The value of our $\\chi^2$ test-statistic is computed as follows:\n",
    "\n",
    "$$\\chi^2=\\frac{\\left(25-20\\right)^2}{25}+\\frac{\\left(25-30\\right)^2}{25}+\\frac{\\left(25-30\\right)^2}{25}+\\frac{\\left(25-20\\right)^2}{25}=4$$\n",
    "\n",
    "To determine whether a $\\chi^2$ test-statistic is statistically significant, we will also need to compute the <a href=\"https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)\">**degrees of freedom**</a>, typically abbreviated as DoF or dof. For a feature with $N$ distinct classes, there are $N-1$ DoF. For example, there are 2 classes for the **bruises** feature: **t** or **f**, and hence only 1 DoF. To get the total DoF from multiple features, simply multiply the DoF for each feature: in our example, there is 1 DoF from the **bruises** feature and 1 DoF from the **edible** feature. The total DoF is simply $1\\times1=1$.\n",
    "\n",
    "Now we can compute the <a href=\"https://en.wikipedia.org/wiki/P-value\">**p-value**</a> of the test-statistic $\\chi^2=4$ with 1 DoF, which is equal to 1 minus the **cumulative distribution function** ([`chi2.cdf` from the `scipy` package](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2.html)). **Run** the cell below to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will use the cumulative distribution function (cdf) and\n",
    "# probability density function (pdf) for the chi2 distribution:\n",
    "from scipy.stats import chi2 as stats_chi2\n",
    "\n",
    "print(\"The p value with chi-squared of {:.2f} and {} DoF is {:.3f}\"\\\n",
    "      .format(4,1,1-stats_chi2.cdf(4,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we get a p-value of 0.046. That means that there is a 4.6% chance of observing a **bruises** and **edible** contingency table deviating at least as far from the expected contingency table as the one above, given the null hypothesis that the two features are independent. The larger the $\\chi^2$ test-statistic is for a contingency table, the lower the resulting p-value and the less likely that two features are independent. However, the critical $\\chi^2$ test-statistic is dependent on the DoF.\n",
    "\n",
    "**Run** the cell below to visualize the $\\chi^2$ distribution for different DoF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize figure and axes:\n",
    "fig, axarr = plt.subplots(1,2)\n",
    "\n",
    "# With two subplots, we want a wider figure aspect ratio:\n",
    "fig.set_size_inches(11,4)\n",
    "\n",
    "# Plot the pdf and cdf for the chi2 distribution for several DoF:\n",
    "x = np.linspace(0,20,1e3)\n",
    "for df in np.arange(1,8):\n",
    "    # probability density function on first axis:\n",
    "    axarr[0].plot(x, stats_chi2.pdf(x,df), label=df, lw=3)\n",
    "    # cumulative distribution function on second axis:\n",
    "    axarr[1].plot(x, stats_chi2.cdf(x,df), label=df, lw=3)\n",
    "    \n",
    "# Set the y limits for each axis separately:\n",
    "ylim = axarr[0].set_ylim([0,0.5])\n",
    "ylim = axarr[1].set_ylim([0,1])\n",
    "\n",
    "# Add a legend to each axis showing the DoF:\n",
    "axarr[0].legend(title=\"DoF ($k$)\")\n",
    "axarr[1].legend(title=\"DoF ($k$)\")\n",
    "\n",
    "# Set the title and axes labels for each axis\n",
    "title   = axarr[0].set_title(\"Probability Density Function\")\n",
    "title   = axarr[1].set_title(\"Cumulative Distribution Function\")\n",
    "x_label = axarr[0].set_xlabel(\"$\\chi^2$\", fontsize=16)\n",
    "x_label = axarr[1].set_xlabel(\"$\\chi^2$\", fontsize=16)\n",
    "y_label = axarr[0].set_ylabel(\"$f_k(\\chi^2)$\", fontsize=16)\n",
    "y_label = axarr[1].set_ylabel(\"$F_k(\\chi^2)$\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the probability density function (pdf) for the $\\chi^2$ distribution broadens and flattens as we increase the DoF, meaning larger $\\chi^2$ test-statistics become more common with increasing DoF.\n",
    "\n",
    "## Performing a Chi-Squared Test with `pandas`\n",
    "\n",
    "We can perform the statistical analysis explained above using `pandas`. First, let's make a contingency table from the UCI MLR Mushroom dataset for the `'bruises'` and `'edible'` features, using [the method `pandas.crosstab()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.crosstab.html). **Run** the cell below to create a contingency table from the Mushroom dataset. We will store the contingency table into the `DataFrame` object `bruises_obs` (for observed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a contingency table\n",
    "bruises_obs = pd.crosstab(mush_df['bruises'],mush_df['edible'])\n",
    "print(\"Observed Frequencies:\")\n",
    "display(bruises_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the **observed** contingency table. We next need the **expected** frequency, assuming the `'bruised'` and `'edible'` features are independent. We can do this using an [outer product](https://docs.scipy.org/doc/numpy/reference/generated/numpy.outer.html) of two `numpy` arrays: the `'bruises'` frequencies and the `'edible'` frequencies, normalized by the total number of observations. **Run** the cell below to compute the theoretical frequencies, storing the result into the `DataFrame` object `bruises_exp` (for expected). Note: we're displaying the expected frequencies rounded to the nearest integer, but they are stored in the `DataFrame` object `bruises_exp` as floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bruises_exp = pd.DataFrame(np.outer(bruises_obs.sum(axis=1),bruises_obs.sum(axis=0))\\\n",
    "                           *1.0 / bruises_obs.sum().sum(),\\\n",
    "                            index = bruises_obs.index,\\\n",
    "                            columns = bruises_obs.columns)\n",
    "print(\"Expected Frequencies (assuming feature independence):\")\n",
    "display(bruises_exp.round(0).astype('int64'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute our $\\chi^2$ statistic using `bruises_obs` and `bruises_exp`. Recall the formula for $\\chi^2$:\n",
    "\n",
    "$$\\chi^2=\\sum_{i=1}^n\\frac{\\left(E_i-O_i\\right)^2}{E_i}$$\n",
    "\n",
    "and also recall the definitions of all the symbols:\n",
    "  - $\\chi^2$ is Pearson's cumulative test statistic, which asymptotically approaches a $\\chi^2$ distribution\n",
    "  - $n$ is the number of cells in the contingency table\n",
    "  - $E_i$ is the **expected** or **theoretical** frequency of the $i^{\\text{th}}$ cell of the contingency table.\n",
    "  - $O_i$ is the **observed** or **actual** frequency of the $i^{\\text{th}}$ cell of the contingency table.\n",
    "  \n",
    "**Run** the cell below to compute the $\\chi^2$ test-statistic and the corresponding p-value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bruises_chi2 = ((bruises_exp - bruises_obs).apply(lambda x: x**2) / bruises_exp).sum().sum()\n",
    "print(\"The chi2 test-statistic is {:.2f}.\".format(bruises_chi2))\n",
    "print(\"The p-value for this chi2 is {:.4e}.\".format(1-stats_chi2.cdf(bruises_chi2,df=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value, or the likelihood of `'edible'` and `'bruises'` being independent features, is practically zero! It's very unlikely that the features are independent, and so there's likely useful predictive power in the `'bruises'` feature. But is it the feature with the *most* predictive power? We'll see in the next section how `sklearn` can use the $\\chi^2$ test-statistic to determine the most useful features to retain. But before we do, let's do some exercises to practice what we've covered so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "You may want to consult the above code cells while working through these exercises.\n",
    "## Question 1\n",
    "Make a contingency table using `pandas.crosstab()` for the `'stalk-shape'` and `'edible'` features, and store the resulting `DataFrame` object into the variable `stalk_obs`. The `'stalk-shape'` feature has two categories: (**e**)nlarging and (**t**)apering. How many (**p**)oisonous mushrooms have an (**e**)nlarging stalk shape? How many (**e**)dible mushrooms have a (**t**)apering stalk shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Here, we will use the contingency table `stalk_obs` from the previous question.\n",
    "  - What does `stalk_obs.sum(axis=0)` compute?\n",
    "  - What does `stalk_obs.sum(axis=1)` compute?\n",
    "  - What does `stalk_obs.sum().sum()` compute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Create a table of the expected or theoretical frequencies, given the assumption that the features `'stalk-shape'` and `'edible'` are independent. Store the result in the variable `stalk_exp`. *Hint:* You can use the observed contingency table `stalk_obs` to compute the expected frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Here, we will use the contingency table `stalk_exp` from the previous question.\n",
    "  - What does `stalk_exp.sum(axis=0)` compute?\n",
    "  - What does `stalk_exp.sum(axis=1)` compute?\n",
    "  - What does `stalk_exp.sum().sum()` compute?\n",
    "  \n",
    "Compare these results to those from question 2. Are the **values** the same? Are the **data types** (`dtype`) the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Recall the formula for the $\\chi^2$ test-statistic:\n",
    "\n",
    "$$\\chi^2=\\sum_{i=1}^n\\frac{\\left(E_i-O_i\\right)^2}{E_i}$$\n",
    "\n",
    "Compute $\\chi^2$ for the two features `'stalk-shape'` and `'edible'`.\n",
    "\n",
    "The $\\chi^2$ test-statistic for the two features `'bruises'` and `'edible'` was 2043.45. How does the $\\chi^2$ test-statistic for the two features `'stalk-shape'` and `'edible'` compare? Can we compare these two $\\chi^2$ test-statistics directly with one another? *Hint:* Do they have the same DoF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Let's tie it all back to feature selection. Suppose we had only the `'bruises'` feature:\n",
    "  - To maximize **accuracy**, should we predict (**e**)dible or (**p**)oisonous if `'bruises'` is (**t**)rue?\n",
    "  - To maximize **accuracy**, should we predict (**e**)dible or (**p**)oisonous if `'bruises'` is (**f**)alse?\n",
    "  - How many mushrooms, out of the 8124 in the mushroom data set, would be correctly classified from only the `'bruises'` feature?\n",
    "  \n",
    "Now suppose we had only the `'stalk-shape'` feature:\n",
    "  - To maximize **accuracy**, should we predict (**e**)dible or (**p**)oisonous if `'stalk-shape'` is (**e**)nlarging?\n",
    "  - To maximize **accuracy**, should we predict (**e**)dible or (**p**)oisonous if `'stalk-shape'` is (**t**)apering?\n",
    "  - How many mushrooms, out of the 8124 in the mushroom data set, would be correctly classified from only the `'stalk-shape'` feature?\n",
    "  \n",
    "Which feature is better to keep, `'bruises'` or `'stalk-shape'`? Does this correspond with your intuition from the $\\chi^2$ test-statistics?\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate feature selection: `SelectKBest`\n",
    "One implication of the [curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality) is that it's useful to reduce the dimensionality of sample sets, either to improve estimatorsâ€™ accuracy scores or to boost their performance on very high-dimensional datasets. [The `feature_selection` module](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) in `sklearn` includes **univariate** filter selection methods, including [the `SelectKBest` class](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html). **Univariate** means that each feature is considered **independently** -- can you think of any pitfalls to univariate feature selection? (Hint: think about the XOR operator...)\n",
    "\n",
    "Let's see how we can use `SelectKBest` to reduce the dimensionality of our mushroom data set. First, we need to do some preprocessing, to ensure that the `sklearn` methods can make predictions. Recall that `sklearn` requires numeric features, and we can use [the `pandas` method `get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) to convert the Categorical features into indicator variables. Each feature with $n$ distinct classes will become $n$ different indicator variables.\n",
    "\n",
    "**Run** the cell below to convert all the features in the mushroom dataset to dummy variables. How many predictive features do we now have to choose from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = mush_df.drop(['edible'], axis=1)\n",
    "y = mush_df['edible']\n",
    "X = pd.get_dummies(X)\n",
    "print(\"There are now {} predictive features to choose from.\".format(len(X.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you check the `sklearn` documentation for `SelectKBest`, you'll find that the first parameter is a callable, `score_func`. The callable `score_func` must take two arrays, X and y, as inputs, and return either an array (of scores) or a pair of arrays (of scores and p-values). There will be one score for each feature in the X array. The `sklearn` [user guide for univariate feature selection](http://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection) lists some possible callables for `score_func`:\n",
    "\n",
    "  - For **regression** problems: [f_regression](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html), [mutual_info_regression](scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html)\n",
    "  - For **classification** problems: [chi2](scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html), [f_classif](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html), [mutual_info_classif](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html)\n",
    "  \n",
    "We spent some time above learning about the $\\chi^2$ test-statistic, so let's use `chi2`. **Run** the cell below to import `chi2` from `sklearn.feature_selection`. Then, compute `chi2` for the two `bruises` indicator variables, `'bruises_f'` and `'bruises_t'`. Is the result equal to the $\\chi^2$ test-statistic of 2043.45 that we computed manually above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "chi2_vals, p_vals = chi2(X[['bruises_f','bruises_t']],y)\n",
    "\n",
    "display(chi2_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get two $\\chi^2$ test-statistic contributions, one for the `'bruises_f'` feature and one for the `'bruises_t'` feature. Let's revisit our manual computation of the $\\chi^2$ test-statistic. We used the formula:\n",
    "\n",
    "$$\\chi^2=\\sum_{i=1}^n\\frac{\\left(E_i-O_i\\right)^2}{E_i}$$\n",
    "\n",
    "where the summation was over *all cells* in the contingency table. We performed the summation over all cells with `.sum().sum()`. What if we only add up the contributions to $\\chi^2$ *row-wise*, with `.sum(axis=1)`? **Run** the cell below and find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "((bruises_exp - bruises_obs).apply(lambda x: x**2) / bruises_exp).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding row-wise, we get the same result for $\\chi^2$ as we do from the `sklearn` `chi2` callable. We also see that the contribution to $\\chi^2$ is greater from the mushrooms with bruises than from those without.\n",
    "\n",
    "The idea behind `SelectKBest` is that the larger the $\\chi^2$ test-statistic is for a given feature, the more predictive power that feature has. So we'll only keep the $k$ features with the largest $\\chi^2$ test-statistics.\n",
    "\n",
    "**Run** the cell below to print the top $k$ features with the largest $\\chi^2$ statistics, in descending order. We'll compare this list to the features selected from `SelectKBest()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set a value for k\n",
    "k = 10\n",
    "\n",
    "# Use the chi2 callable to compute the chi2_vals and p_vals\n",
    "chi2_vals, p_vals = chi2(X,y)\n",
    "\n",
    "# Use argsort()[-k:] to get the indices of the last k sorted chi2_values\n",
    "# Use [::-1] to reverse the array (chi2 in descending order).\n",
    "for feature in X.columns[chi2_vals.argsort()[-k:][::-1]]:\n",
    "    print(feature) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now **run** the cell below to use `SelectKBest`, which essentially is a wrapper for all the steps we did above. Do we find the same $k$ best features as above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "# Import SelectKBest from sklearn.feature_selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "print(\"Selecting the {} best features using SelectKBest:\"\\\n",
    "      .format(k))\n",
    "\n",
    "# Keep track of elapsed time to determine\n",
    "# the k best features with the chi2 score_func:\n",
    "t0 = time()\n",
    "\n",
    "# Create a SelectKBest() object, top_feat, with chi2 as score_func\n",
    "top_feat = SelectKBest(chi2, k)\n",
    "\n",
    "# Fit top_feat to data, then transform it\n",
    "X_kbest = top_feat.fit_transform(X,y)\n",
    "\n",
    "# Print out the elapsed time for fitting the classifier\n",
    "print(\"  ...done in {:0.3f}s\\n\".format(time() - t0))\n",
    "\n",
    "# Print the number of features remaining after calling SelectKBest\n",
    "print(\"There are {} features after calling SelectKBest:\".format(X_kbest.shape[1]))\n",
    "\n",
    "# top_feat is already fit to the data, so use it to get the column names\n",
    "# of the k best features (note, they will NOT be in descending order)\n",
    "k_best_features = X.columns[top_feat.transform(np.arange(len(X.columns)).reshape(1,-1))][0]\n",
    "for feature in k_best_features:\n",
    "    print(\"  {}\".format(feature))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the same $k$ features as we found above, but this time they appear in the same order as they do in the original `mush_df` `DataFrame` object. Now we're free to build a model on this smaller data set, hopefully preserving the features with the greatest individual predictive power to determine whether or not a mushroom is edible. **Run** the cell below to create a `RandomForestClassifier()` that predicts using only the $k$ best features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "print(\"Creating a Random Forest Classifier using {} best features:\"\\\n",
    "      .format(X_kbest.shape[1]))\n",
    "\n",
    "# Keep track of elapsed time to fit the Random Forest\n",
    "# classifier on the k best features:\n",
    "t0 = time()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "            X_kbest, y, test_size=0.20, random_state=0)\n",
    "\n",
    "# Create a Random Forest classifier with 10 trees in the forest\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None,\\\n",
    "                             min_samples_split=2, random_state=0)\n",
    "\n",
    "# Fit the classifier on the training data\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# Print out the elapsed time for fitting the classifier\n",
    "print(\"  ...done in {:0.3f}s\".format(time() - t0))\n",
    "\n",
    "# Display the accuracy score on the test set\n",
    "print(\"  test set accuracy: {:.2f}%\"\\\n",
    "      .format(accuracy_score(y_test,clf.predict(X_test))*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination\n",
    "\n",
    "Univariate feature selection, described above, is one way to reduce the dimensionality of a dataset, but it is not without its faults:\n",
    "  - Features that are useful when combined (*e.g.* the XOR operator) would be ignored.\n",
    "  - The particular instances or inputs that are correctly classified do not shape the feature selection process.\n",
    "\n",
    "An alternative approach would be to use [**recursive feature elimination (RFE)**](http://scikit-learn.org/stable/modules/feature_selection.html#rfe). With RFE, an estimator is first trained on the initial set of features. During the training step, weights are assigned to each feature. Next, features whose absolute weights are the **smallest** are pruned from the set. The idea is that the feature with the smallest absolute weight would change the model the least if it were removed from the set of features. This procedure is repeated until the desired number of features is reached.\n",
    "\n",
    "Let's take a peek in [the `sklearn` documentation for `RFE`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html). Note that the `estimator` parameter must have a `coef_` attribute that, after fitting with the `fit` method, holds the fitted parameters. More important features must correspond to higher absolute values of `coef_`. But alas, if we check the `RandomForestClassifier` documentation, there is no `coef_` attribute! However, there is a `feature_importances_` attribute that ranks the model features by importance. A simple adaptation, [suggested by user A.P. on Stack Overflow](http://stackoverflow.com/questions/24123498/recursive-feature-elimination-on-random-forest-using-scikit-learn), shows how to make `RandomForestClassifier` compatible with `RFE`. **Run** the cell below to perform recursive feature elimination on the mushroom data set. Does it take longer than `SelectKBest()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the Recursive Feature Elimination (RFE) selector:\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Adapt the RandomForestClassifier class to be compatible with RFE:\n",
    "class RandomForestClassifierWithCoef(RandomForestClassifier):\n",
    "    def fit(self, *args, **kwargs):\n",
    "        super(RandomForestClassifierWithCoef, self).fit(*args, **kwargs)\n",
    "        # Add the coef_ attribute, required for RFE:\n",
    "        self.coef_ = self.feature_importances_\n",
    "\n",
    "# Number of features at which to cease RFE\n",
    "n_feat = 10\n",
    "\n",
    "# Number of features to remove at each step of RFE\n",
    "step = 1\n",
    "\n",
    "print(\"Creating a Random Forest Classifier\")\n",
    "print(\"  RFE, removing {} feature(s) at a time, until reaching {} features.\"\\\n",
    "      .format(step,n_feat))\n",
    "\n",
    "# Keep track of elapsed time to recursively eliminate\n",
    "# all but n_feat features:\n",
    "t0 = time()\n",
    "\n",
    "# Create a Random Forest classifier with 10 trees in the forest\n",
    "clf = RandomForestClassifierWithCoef(n_estimators=10, max_depth=None,\\\n",
    "                                    min_samples_split=2, random_state=0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "            X, y, test_size=0.20, random_state=0)\n",
    "\n",
    "# Create a RFE selector, using the Random Forest classifier as the estimator\n",
    "selector = RFE(clf, n_features_to_select=n_feat, step=step)\n",
    "\n",
    "# Fit the RFE selector (this is the time-intensive step)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "# Print out the elapsed time for RFE\n",
    "print(\"  ...done in {:0.3f}s\".format(time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `RFE` is a bit slower than `SelectKBest()`, simply because `RFE` is more labor intensive. A `RandomForestClassifier` is built at every step, and only one feature is removed at every step. With over 110 features in the initial dataset, that means over 100 `RandomForestClassifier` estimators will be fit to the dataset, each comprising 10 decision trees. In contrast, `SelectKBest()` only needs to compute the value of $\\chi^2$ for each feature once.\n",
    "\n",
    "Let's see the final result. **Run** the cell below to print a list of the ten features remaining after recursive feature elimination. From the `RFE` object, we are using the `support_` attribute, which is a boolean array equal to `True` only at the indices of the remaining features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the names of the features remaining after RFE\n",
    "RFE_best_features = X.columns[selector.support_]\n",
    "\n",
    "# Print the remaining feature names:\n",
    "for feature in RFE_best_features:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the list of features that remain after `RFE`. How many of these features were also chosen by `SelectKBest()`?\n",
    "\n",
    "Now **run** the cell below to see how well these features predict on the test data. From the `RFE` object, we are using the `estimator_` attribute, which is the `RandomForestClassifierWithCoef` estimator, fit on the reduced dataset. Does this set of 10 features make a better prediction than the set of 10 from `SelectKBest()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display the accuracy score on the test set\n",
    "print(\"Test set accuracy: {:.2f}%\".format(\\\n",
    "    accuracy_score(y_test, selector.estimator_.predict(X_test[RFE_best_features]))*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing... what if we don't want to tell `RFE` *a priori* how many features to prune? We can use [the `RFECV` class](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html)! This class performs feature ranking with recursive feature elimination and cross-validated selection of the best number of features. **Run** the cell below to use `RFECV` to prune the mushroom data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# Number of features to remove at each step of RFE\n",
    "step = 1\n",
    "\n",
    "print(\"Creating a Random Forest Classifier\")\n",
    "print(\"  RFECV, removing {} feature(s) at a time.\"\\\n",
    "      .format(step))\n",
    "\n",
    "# Keep track of elapsed time to recursively eliminate features:\n",
    "t0 = time()\n",
    "\n",
    "# Create a Random Forest classifier with 10 trees in the forest\n",
    "clf = RandomForestClassifierWithCoef(n_estimators=10, max_depth=None,\\\n",
    "                                    min_samples_split=2, random_state=0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "            X, y, test_size=0.20, random_state=0)\n",
    "\n",
    "# Create a RFECV selector, using the Random Forest classifier as the estimator\n",
    "# with five-fold cross-validation (cv=5)\n",
    "# n_jobs = -1 sets the number of jobs to run in parallel equal to the\n",
    "# number of cores on your machine.\n",
    "selector = RFECV(clf, step=step, cv=5, n_jobs=-1,\n",
    "              scoring='accuracy')\n",
    "\n",
    "# Fit the RFE selector (this is the time-intensive step)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "# Print out the elapsed time for RFE\n",
    "print(\"  ...done in {:0.3f}s\".format(time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That took a little bit longer than `RFE`... let's see the results. **Run** the cell below to see how many of the 117 original features from the mushroom data set remain after pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(selector.n_features_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No features were removed! That's a bit anticlimactic, no? We can look into the `grid_scores_` attribute to see how well each of the numbers of features performed. **Run** the cell below to print and plot the cross-validation scores for each number of features retained. Do you notice something peculiar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(selector.grid_scores_)\n",
    "\n",
    "# Initialize figure and axes:\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(selector.grid_scores_))+1,selector.grid_scores_)\n",
    "xlim = ax.set_xlim([0,120])\n",
    "ylim = ax.set_ylim([0,1.01])\n",
    "xlab = ax.set_xlabel('Number of Features Retained After RFE')\n",
    "ylab = ax.set_ylabel('Cross Validation Score')\n",
    "titl = ax.set_title('CV Score vs. Number of Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out with this problem, we're in a bit of a funny edge case for `RFECV`. The `RandomForestClassifier` works so well that every model containg from 14 features up to 117 features gets a perfect cross-validation score! Most prediction problems would not be able to achieve a perfect cross-validation score even once, but the mushroom data set is a little too well-behaved. Ideally, in the event of a cross-validation score tie, we would want `RFECV` (a tool used for dimensionality reduction) to select the *fewest* number of features, and not the greatest. As of `sklearn` version 0.18.1, `RFECV` selects the model with the greatest number of features in the event of a tie -- hopefully this will be fixed in a later version.\n",
    "\n",
    "Anyway, not all is lost. We saw above, looking at the `grid_scores_` attribute, that we can prune the data set down to 14 features and still get optimal predictive power. **Run** the cell below to create a [parsimonious](https://www.merriam-webster.com/dictionary/parsimonious) `RandomForestClassifier()` for the mushroom data set, and confirm that the accuracy scores on both the training and testing sets are optimal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of features at which to cease RFE\n",
    "n_feat = 14\n",
    "\n",
    "# Number of features to remove at each step of RFE\n",
    "step = 1\n",
    "\n",
    "print(\"Creating a Random Forest Classifier\")\n",
    "print(\"  RFE, removing {} feature(s) at a time, until reaching {} features.\"\\\n",
    "      .format(step,n_feat))\n",
    "\n",
    "# Keep track of elapsed time to recursively eliminate\n",
    "# all but n_feat features:\n",
    "t0 = time()\n",
    "\n",
    "# Create a Random Forest classifier with 10 trees in the forest\n",
    "clf = RandomForestClassifierWithCoef(n_estimators=10, max_depth=None,\\\n",
    "                                    min_samples_split=2, random_state=0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "            X, y, test_size=0.20, random_state=0)\n",
    "\n",
    "# Create a RFE selector, using the Random Forest classifier as the estimator\n",
    "selector = RFE(clf, n_features_to_select=n_feat, step=step)\n",
    "\n",
    "# Fit the RFE selector (this is the time-intensive step)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "# Print out the elapsed time for RFE\n",
    "print(\"  ...done in {:0.3f}s\".format(time() - t0))\n",
    "\n",
    "# Get the names of the features remaining after RFE\n",
    "RFE_best_features = X.columns[selector.support_]\n",
    "\n",
    "# Display the accuracy score on the test set\n",
    "print(\"Training set accuracy: {:.2f}%\".format(\\\n",
    "    accuracy_score(y_train, selector.estimator_.predict(X_train[RFE_best_features]))*100.0))\n",
    "\n",
    "# Display the accuracy score on the test set\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(\\\n",
    "    accuracy_score(y_test, selector.estimator_.predict(X_test[RFE_best_features]))*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection - Recap\n",
    "\n",
    "So what feature selection techniques did we cover in this notebook?\n",
    "\n",
    "We learned about **univariate feature selection** and `SelectKBest()`. Univariate feature selection seems to be a computationally inexpensive way to pare down the dimensionality of a data set, but at the expense of missing out on features that work well in tandem. We needed a score function to determine the predictive power of each feature. For classification problems, we learned about the **Chi-Squared** $(\\chi^2)$ test statistic, which is one possible score function for `SelectKBest()`. As the value of $\\chi^2$ increases for a pair of features, it becomes less likely that the two features are independent.\n",
    "\n",
    "We also learned about two ways to approach **recursive feature elimination**: `RFE()` and `RFECV()`. With the former (`RFE`), you need to prescribe *a priori* the number of features you'd like to retain for the final model. With the latter (`RFECV`), cross-validation scores are used to rank each number of features, and the final model will have a number of features that maximizes the cross-validation score. We saw that it's important that the fit estimator have some `coef_` attribute that contains a value for each feature, increasing with increasing feature importance. We also saw that RFE is a bit more computationally expensive than univariate feature selection. However, RFE generally yields better results than univariate feature selection for the same number of features, because RFE can capture more complex relationships (think XOR operator).\n",
    "\n",
    "For further reading on feature selection, you could check out the `sklearn.feature_selection` [userguide](http://scikit-learn.org/stable/modules/feature_selection.html#feature-selection) and [API](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection), [this example](http://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html) of `RFE` from the `sklearn` documentation, and [this blogpost from machinelearningmastery](http://machinelearningmastery.com/feature-selection-machine-learning-python/).\n",
    "\n",
    "In addition to feature selection, you may also use **feature transformation** to reduce the dimensionality of a dataset, including Principal Component Analysis (PCA) which we discussed in lesson-06-part-02."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
